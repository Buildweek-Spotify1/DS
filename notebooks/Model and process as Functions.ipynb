{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Functions.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JVnGZ7B5uus3",
        "colab_type": "text"
      },
      "source": [
        "# Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3M0UdLpgugVw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "outputId": "6bff32d6-95d2-43eb-fe9d-384d684f079d"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np \n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "!pip install category_encoders==2.*\n",
        "import category_encoders as ce \n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "\n",
        "# for modeling\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Collecting category_encoders==2.*\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/44/57/fcef41c248701ee62e8325026b90c432adea35555cbc870aff9cfba23727/category_encoders-2.2.2-py2.py3-none-any.whl (80kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 2.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.6/dist-packages (from category_encoders==2.*) (0.10.2)\n",
            "Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders==2.*) (0.5.1)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from category_encoders==2.*) (1.18.5)\n",
            "Requirement already satisfied: pandas>=0.21.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders==2.*) (1.0.5)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from category_encoders==2.*) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.6/dist-packages (from category_encoders==2.*) (0.22.2.post1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from patsy>=0.5.1->category_encoders==2.*) (1.15.0)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21.1->category_encoders==2.*) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21.1->category_encoders==2.*) (2018.9)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.20.0->category_encoders==2.*) (0.16.0)\n",
            "Installing collected packages: category-encoders\n",
            "Successfully installed category-encoders-2.2.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QLw--1pBvV7Z",
        "colab_type": "text"
      },
      "source": [
        "# Classes first"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZYPjaXFDvXUH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Songs(DB.Model):\n",
        "    \"\"\" ##############################FOR EXAMPLE ONLY:\n",
        "    __tablename__ = \"Songs\"\n",
        "    id = DB.Column(DB.BigInteger, primary_key=True)\n",
        "    genre = DB.Column(DB.String(50))\n",
        "    artist_name = DB.Column(DB.String(50))\n",
        "    track_name = DB.Column(DB.String(100))\n",
        "    track_id = DB.Column(DB.String(50))\n",
        "    popularity = DB.Column(DB.Integer)\n",
        "    acousticness = DB.Column(DB.Float)\n",
        "    danceability = DB.Column(DB.Float)\n",
        "    duration_ms = DB.Column(DB.Integer)\n",
        "    energy = DB.Column(DB.Float)\n",
        "    instrumentalness = DB.Column(DB.Float)\n",
        "    key = DB.Column(DB.Integer)\n",
        "    liveness = DB.Column(DB.Float)\n",
        "    loudness = DB.Column(DB.Float)\n",
        "    mode = DB.Column(DB.Integer)\n",
        "    speechiness = DB.Column(DB.Float)\n",
        "    tempo = DB.Column(DB.Float)\n",
        "    time_signature = DB.Column(DB.Integer)\n",
        "    valence = DB.Column(DB.Float)\n",
        "\n",
        "    def __repr__(self):\n",
        "        return '<Song {}>'.format(self.track_name)\n",
        "        \"\"\"\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97eacdulvj9I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class My_encoder(BaseEstimator, TransformerMixin):\n",
        "   \n",
        "    def __init__(self,drop = 'first',sparse=False):\n",
        "        self.encoder = OneHotEncoder(drop = drop,sparse = sparse)\n",
        "        self.features_to_encode = []\n",
        "        self.columns = []\n",
        "    \n",
        "    def fit(self,X_train,features_to_encode):\n",
        "        \n",
        "        data = X_train.copy()\n",
        "        self.features_to_encode = features_to_encode\n",
        "        data_to_encode = data[self.features_to_encode]\n",
        "        self.columns = pd.get_dummies(data_to_encode,drop_first = True).columns\n",
        "        self.encoder.fit(data_to_encode)\n",
        "        return self.encoder\n",
        "    \n",
        "    def transform(self,X_test):\n",
        "        \n",
        "        data = X_test.copy()\n",
        "        data.reset_index(drop = True,inplace =True)\n",
        "        data_to_encode = data[self.features_to_encode]\n",
        "        data_left = data.drop(self.features_to_encode,axis = 1)\n",
        "        \n",
        "        data_encoded = pd.DataFrame(self.encoder.transform(data_to_encode),columns = self.columns)\n",
        "        \n",
        "        return pd.concat([data_left,data_encoded],axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MSi8rAqE0AEV",
        "colab_type": "text"
      },
      "source": [
        "# Now for the functions: my suggested approach is instantiating the model when we instantiate the app:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6hKy3dCuzHV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# our functions would sit inside the flask create_app(): function (assuming flask app instantiated)\n",
        "def create_app(): #notice that all the functions below are part of the app:\n",
        "\n",
        "  #app = Flask(__name__)\n",
        "\n",
        "  def pre_process(df):\n",
        "    #Encoding\n",
        "    features_to_encode = ['time_signature', 'mode', 'key', 'genre']\n",
        "    enc= My_encoder()\n",
        "    enc.fit(df,features_to_encode)\n",
        "    df_encoded = enc.transform(df)\n",
        "    #return df_encoded\n",
        "    #Scaling - after reading up on the spotify method for grading these features, I think we can do without it.\n",
        "    #scaler = StandardScaler()\n",
        "    \"\"\"scaleCols = ['popularity',\t'acousticness',\t'danceability',\t'duration_ms',\t'energy',\n",
        "              'instrumentalness',\t'liveness',\t'loudness',\t'speechiness',\t'tempo',\t\n",
        "              'valence',\t'time_signature_1/4',\t'time_signature_3/4',\t'time_signature_4/4',\t\n",
        "              'time_signature_5/4',\t'mode_Minor',\t'key_A#',\t'key_B',\t'key_C',\n",
        "              'key_C#',\t'key_D',\t'key_D#', 'key_E',\t'key_F',\t'key_F#',\t'key_G',\t\n",
        "              'key_G#',\t'genre_Alternative',\t'genre_Anime',\t'genre_Blues',\n",
        "              \"genre_Children's Music\",\t\"genre_Children’s Music\",\t'genre_Classical', \n",
        "              'genre_Comedy',\t'genre_Country',\t'genre_Dance',\t'genre_Electronic',\t'genre_Folk',\n",
        "              'genre_Hip-Hop',\t'genre_Indie',\t'genre_Jazz',\t'genre_Movie',\t'genre_Opera',\t\n",
        "              'genre_Pop',\t'genre_R&B',\t'genre_Rap',\t'genre_Reggae',\t'genre_Reggaeton',\n",
        "              'genre_Rock',\t'genre_Ska',\t'genre_Soul',\t'genre_Soundtrack',\t'genre_World']\n",
        "\n",
        "    df_scaled = scaler.fit_transform(df_encoded[scaleCols])\n",
        "    \"\"\"\n",
        "    return df_encoded\n",
        "\n",
        "\n",
        "  \"\"\" Now Instantiating the Model when we instantiate the app \"\"\"\n",
        "\n",
        "  df_encoded = pre_process(df)\n",
        "\n",
        "  neigh = NearestNeighbors(n_neighbors=15)\n",
        "  features = ['acousticness', 'danceability', 'energy', 'instrumentalness',\n",
        "              'liveness', 'loudness', 'speechiness', 'tempo','valence', \n",
        "             \t'time_signature_1/4',\t'time_signature_3/4',\t'time_signature_4/4',\n",
        "            \t'time_signature_5/4',\t'mode_Minor',\t'key_A#',\t'key_B',\t'key_C',\n",
        "            \t'key_C#',\t'key_D',\t'key_D#',\t'key_E','key_F',\t'key_F#',\t'key_G',\t'key_G#']\n",
        "  X = df_encoded[features].values\n",
        "  neigh.fit(X)\n",
        "  \n",
        "  '''\n",
        "        Takes in a dataframe, a feature set array and a song ID and \n",
        "        returns a list of tuples of Artist Name and Track Name\n",
        "    '''\n",
        "    def closest_ten(df: pd.DataFrame, X_array: np.ndarray, song_id: int) -> List[Tuple]:\n",
        "        song = df.iloc[song_id]\n",
        "        X_song = X[song_id]\n",
        "        _, neighbors = neigh.kneighbors(np.array([X_song]))\n",
        "        return neighbors[0][1:]\n",
        "    \n",
        "    # accepts the cursor and the row as a tuple and returns a dictionary result and you can object column by name \n",
        "    def dict_factory(cursor, row):\n",
        "        d = {}\n",
        "        for idx, col in enumerate(cursor.description):\n",
        "            d[col[0]] = row[idx]\n",
        "        return d\n",
        "\n",
        "    ''' PROPOSAL:\n",
        "        Main API route that takes in a Track ID sent from the user and pairs it with\n",
        "        a unique track_id from the database and returns the closest songs from our\n",
        "        Machine Learning model.\n",
        "    '''\n",
        "    @app.route('/track/<track_id>', methods=['GET'])\n",
        "    def track(track_id):\n",
        "        track_id = int(track_id)\n",
        "        conn = sqlite3.connect('Spotify_Songs.db')\n",
        "        conn.row_factory = dict_factory\n",
        "        curs = conn.cursor()\n",
        "        songlist = []\n",
        "        song_recs = closest_ten(df, X, track_id)\n",
        "        for idx in song_recs:\n",
        "            song = curs.execute(\n",
        "                f'SELECT DISTINCT * FROM Songs WHERE id=={idx};').fetchone()\n",
        "            songlist.append(song)\n",
        "        return jsonify(songlist)\n",
        "\n",
        "    return app\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lb9kiC_3v7Kd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}